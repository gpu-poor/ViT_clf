{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ViTFeatureExtractor, ViTModel, ViTForImageClassification, ViTConfig\n",
    "# from PIL import Image\n",
    "# import requests\n",
    "\n",
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "# model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/8f/b435e010927ab2e8e7708464e5f47f233f10d8d71d73a3d5c7c456346a4f/Pillow-8.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-8.3.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install jupyter-lab\n",
    "#!pip install numpy==1.19.5\n",
    "#!pip install pandas==1.1.3\n",
    "#!pip install opencv-python==4.2.0.34\n",
    "#!pip install torch==1.8.1\n",
    "#!pip install pytorch-lightning==1.4.6\n",
    "#!pip install transformers==4.10.2\n",
    "#!pip install scikit-learn==0.24.2\n",
    "#!pip install Pillow==8.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTModel, ViTForImageClassification, ViTConfig\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# pytorch related imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "#from torchvision.datasets import CIFAR10\n",
    "#from torchvision import transforms\n",
    "\n",
    "# lightning related imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# sklearn related imports\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class firesmoke_image_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file_path, image_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        row = self.data_frame.iloc[index]\n",
    "        image_path = self.image_dir+\"/\"+row['image_name'].strip()\n",
    "        \n",
    "        img = cv2.imread(image_path)\n",
    "       \n",
    "        #img = np.einsum(\"ijk->kij\", img)\n",
    "        img = self.feature_extractor(img)['pixel_values'][0] # Don't forget this to apply while inference\n",
    "        #img = image = Image.open(image_path)\n",
    "        label = row[1]#.to_numpy(dtype=np.float32)\n",
    "        if self.transform:\n",
    "            img = transform(img)\n",
    "            #img = feature_extractor(img)['pixel_values'][0]\n",
    "            \n",
    "        return [img, label]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = firesmoke_image_dataset(\"/home/anish/multilabel_classification/sample_data/image_label.csv\",\n",
    "                                  \"/home/anish/multilabel_classification/sample_data/images/\" )\n",
    "dl = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "b = None\n",
    "for batch in dl:\n",
    "    b = batch\n",
    "    break\n",
    "\n",
    "#op = model(pixel_values=b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.pooler_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating pl datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireSmokeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, csv_file_path, data_dir: str = './', batch_size=5):\n",
    "        super().__init__()\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "#         self.transform = transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         ])\n",
    "        \n",
    "#         self.dims = (3, 32, 32)\n",
    "#         self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download \n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.firesmoke_ds = firesmoke_image_dataset(self.csv_file_path, self.data_dir)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.firesmoke_ds, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.firesmoke_ds, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.firesmoke_ds, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pl lightningModule for vision transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTfinetune(pl.LightningModule):\n",
    "    def __init__(self, num_classes, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        pooler_dims = 768\n",
    "        self.vit_back_bone = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.fc  = nn.Sequential(\n",
    "                              nn.Dropout(0.5),\n",
    "                              nn.Linear(768, num_classes)\n",
    "                             )\n",
    "        self.learning_rate = learning_rate\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.vit_back_bone(pixel_values=x)\n",
    "        x = x.pooler_output\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    # logic for a single training step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    # logic for a single validation step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # logic for a single testing step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = ViTfinetune(num_classes=5)\n",
    "lsm = ft(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(lsm , dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1577, -1.5392, -1.9584, -1.0667, -1.6895],\n",
       "        [-1.4025, -1.6001, -1.7671, -1.9649, -1.4224]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   patience=3,\n",
    "   verbose=False,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "MODEL_CKPT_PATH = 'model/'\n",
    "MODEL_CKPT = 'model-{epoch:02d}-{val_loss:.2f}'\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=MODEL_CKPT_PATH,\n",
    "    monitor='val_loss',\n",
    "    filename=MODEL_CKPT ,\n",
    "    save_top_k=3,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]), torch.Size([2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_FILE=\"/home/anish/multilabel_classification/sample_data/image_label.csv\"\n",
    "IMAGE_DIR = \"/home/anish/multilabel_classification/sample_data/images/\"\n",
    "# Init our data pipeline\n",
    "dm = FireSmokeDataModule(csv_file_path=CSV_FILE, data_dir=IMAGE_DIR, batch_size=2)\n",
    "# To access the x_dataloader we need to call prepare_data and setup.\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/anish/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | vit_back_bone | ViTModel   | 86.4 M\n",
      "1 | fc            | Sequential | 3.1 K \n",
      "---------------------------------------------\n",
      "86.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "86.4 M    Total params\n",
      "345.569   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fa0a86eaec4e1c959eb37638e28e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layoutâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anish/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/anish/miniconda3/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.functional.classification.accuracy.accuracy`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "/home/anish/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/anish/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:322: UserWarning: The number of training samples (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4a59b1b56549b88d9bb6bccbc12720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anish/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1046: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "/home/anish/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651366e4d16c43d9865e986d1bead6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 1.0, 'test_loss': 0.0026426888071000576}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0026426888071000576, 'test_acc': 1.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init our model\n",
    "model = ViTfinetune(num_classes=4)\n",
    "tb_logger = TensorBoardLogger(\"logs/\")\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=50,\n",
    "                     progress_bar_refresh_rate=20, \n",
    "                     gpus=0, \n",
    "                     logger=tb_logger,\n",
    "                     callbacks=[early_stop_callback, checkpoint_callback])\n",
    "\n",
    "# Train the model âš¡ðŸš…âš¡\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Evaluate the model on the held-out test set âš¡âš¡\n",
    "trainer.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [m for m in model.modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = nn.Sequential(*lst[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_model(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
